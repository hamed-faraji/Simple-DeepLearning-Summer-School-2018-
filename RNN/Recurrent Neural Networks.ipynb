{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential MNIST with RNNs\n",
    "In This section we are going to classify MNIST dataset sequentially using RNNs.\n",
    "IMAGE\n",
    "\n",
    "**0. In the first cell, all required packages and functions/classes are imported.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import what you need\n",
    "import keras\n",
    "import matplotlib.pyplot as plt #This package is for plotting\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, SimpleRNN, LSTM, GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Preparing data:**\n",
    "In this cell, following steps should be taken: \n",
    "* Load Train and Test data (use mnist.load_data())\n",
    "* normalize data by deviding by its max (use numpy max function)\n",
    "* change representation of label data to one-hot (use keras.utils.to_categorical)\n",
    "* print the shape of all data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "train data dim: (60000, 28, 28)\n",
      "test data dim: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(np.max(x_train))\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "print('train data dim:', x_train.shape)\n",
    "print('test data dim:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Define Model**\n",
    "* (2.1) Determine number of hidden units(nb_units) for the RNN cell, sequence length, and feature size.\n",
    "* (2.2) We are going to create a Sequential model.\n",
    "* (2.3) Add a SimpleRNN layer to the model. (giving nb_units as the argument and input shape to the cell is enough).\n",
    "* (2.4) We should map the output of RNN cell (with size of nb_units) to our 10 class using a Dense layer. \n",
    "* (2.5) Use categorical_crossentropy as your loss and adam as your optimizer. You may add your desired metrics (accuracy is suggested).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 50)                3950      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 4,460\n",
      "Trainable params: 4,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Determine the following variables:\n",
    "nb_units = 50\n",
    "seq_length = 28\n",
    "feature_size = 28\n",
    "# 2.2 Define a Sequential model. \n",
    "model = Sequential()\n",
    "# 2.3 Add a SimpleRNN layer (search the documenation for its parameters)\n",
    "model.add(SimpleRNN(nb_units, input_shape=(seq_length, feature_size)))\n",
    "# 2.4 Add a Dense layer (search the documenation for its parameters)\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "# 2.5 Compile the model.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 2.6 Print out model.summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Training**\n",
    "Simply Train the model using model.fit (check its parameter in keras documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 0.6426 - acc: 0.7979\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.3250 - acc: 0.9041\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.2554 - acc: 0.9254\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.2153 - acc: 0.9373\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.1985 - acc: 0.9427\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.1850 - acc: 0.9468\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.1733 - acc: 0.9503\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.1680 - acc: 0.9513\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 0.1596 - acc: 0.9542\n",
      "Epoch 10/10\n",
      "50880/60000 [========================>.....] - ETA: 2s - loss: 0.1508 - acc: 0.9571"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "# Complete following line, using  batch_size=128 is suggested.\n",
    "history = model.fit(x_train, y_train, batch_size=32,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
