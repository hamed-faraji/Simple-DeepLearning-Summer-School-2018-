{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. What We Are Going To Do:\n",
    "We are going to classify images of handwritten digits (MNIST dataset) using a fully-connected neural network.\n",
    "After successful training, our model will be able to guess digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt #This package is for plotting\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data:\n",
    "\n",
    "The dataset is loaded in this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data dim: (60000, 28, 28)\n",
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('train data dim:', x_train.shape)\n",
    "print(np.max(x_train))\n",
    "print(np.min(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "rand_num = np.random.randint(len(x_train))\n",
    "\n",
    "plt.imshow(x_train[rand_num],cmap='gray')\n",
    "plt.show()\n",
    "print(y_train[rand_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our Network accept 1D data. So we flatten our 2D image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = len(x_train[0])*len(x_train[0][0])\n",
    "x_train = np.reshape(x_train,(len(x_train), temp))\n",
    "x_test = np.reshape(x_test,(len(x_test), temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize data by rescaling them to (0,1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/np.max(x_train)\n",
    "x_test = x_test/np.max(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert label arrays to 1-hot representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Model\n",
    "**Add the following layers to the network:**\n",
    "* Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "* Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "* Outout Layer: Fully Connected + Softmax Activition (e.g 10 Neurons) calasses:[0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Hidden Layer1:\n",
    "model.add(Dense(512, activation='relu',kernel_initializer = RandomNormal(0,0.01), input_shape=(temp,)))\n",
    "# Hidden Layer2:\n",
    "model.add(Dense(512, activation='relu',kernel_initializer = RandomNormal(0,0.01)))\n",
    "# Output Layer1:\n",
    "model.add(Dense(10, activation='softmax',kernel_initializer = RandomNormal(0,0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine loss function, optimizer and metrics for the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the optimizer and its learning rate\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the review of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Here we saved the raw model without any training. we will use it later.\n",
    "model.save('raw_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train And Evaluate Model. \n",
    "**Train model on training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 45s 743us/step - loss: 2.0358 - acc: 0.3699 - val_loss: 4.2829 - val_acc: 0.7188\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 46s 760us/step - loss: 0.6132 - acc: 0.8201 - val_loss: 2.0547 - val_acc: 0.8700\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 42s 702us/step - loss: 0.3988 - acc: 0.8860 - val_loss: 1.6768 - val_acc: 0.8939\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=32,epochs=3,verbose=1,validation_data=(x_test, y_test),validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate model on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 155us/step\n",
      "[1.6768255846023559, 0.8939]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**\n",
    "\n",
    "In Keras, you can save the model to a HDF5 file(.h5) and reload it later simply by model.save(filepath) and keras.models.load_model(filepath), respectively.\n",
    "\n",
    "The saved model contains:\n",
    "* the architecture of the model, allowing to re-create the model\n",
    "* the weights of the model\n",
    "* the training configuration (loss, optimizer)\n",
    "* the state of the optimizer, allowing to resume training exactly where you left off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mlp.h5')\n",
    "# Delete model to make sure you reload it correctly:\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model and Predict label for a random image in train set. Verify predicted label by ploting the image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('mlp.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(len(x_test))\n",
    "print(model.predict(x_test)[a])\n",
    "print(y_test[a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continue training + Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 37s 779us/step - loss: 0.3467 - acc: 0.9016 - val_loss: 0.3031 - val_acc: 0.9148\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 35s 732us/step - loss: 0.3115 - acc: 0.9113 - val_loss: 0.2770 - val_acc: 0.9213\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 35s 729us/step - loss: 0.2808 - acc: 0.9198 - val_loss: 0.2501 - val_acc: 0.9303\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 36s 745us/step - loss: 0.2526 - acc: 0.9278 - val_loss: 0.2325 - val_acc: 0.9357\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 36s 742us/step - loss: 0.2280 - acc: 0.9350 - val_loss: 0.2099 - val_acc: 0.9425\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 35s 737us/step - loss: 0.2062 - acc: 0.9419 - val_loss: 0.1926 - val_acc: 0.9460\n",
      "Epoch 7/100\n",
      "32736/48000 [===================>..........] - ETA: 11s - loss: 0.1895 - acc: 0.9469"
     ]
    }
   ],
   "source": [
    "# We will use two callbacks here: EarlyStopping, CSVLogger (you may add other callbacks to this list)\n",
    "callback = [keras.callbacks.EarlyStopping(monitor='val_acc', verbose=1, min_delta=0.01, patience = 2, mode = 'max'),\n",
    "            keras.callbacks.CSVLogger('log.csv'),keras.callbacks.BaseLogger(stateful_metrics=None)]\n",
    "history = model.fit(x_train, y_train,batch_size = 32,epochs = 100,verbose = 1,validation_split = 0.2,callbacks = callback)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['acc'])\n",
    "plt.title('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
